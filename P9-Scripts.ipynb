{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e69068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from scipy.spatial import distance\n",
    "import random\n",
    "import time\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "#conda install -c conda-forge implicit\n",
    "import implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5a8b55",
   "metadata": {},
   "source": [
    "### Chargement et préparation de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e7f9df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1513144419000</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1405341936000</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1408667706000</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  category_id  created_at_ts  publisher_id  words_count\n",
       "0           0            0  1513144419000             0          168\n",
       "1           1            1  1405341936000             0          189\n",
       "2           2            1  1408667706000             0          250"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata = pd.read_csv(\"data/articles_metadata.csv\")\n",
    "df_metadata.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de3bd1f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea381a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Chargement des embeddings des articles\n",
    "with open(\"./data/articles_embeddings.pickle\", \"rb\") as input_file:\n",
    "    embeddings = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eac7e40",
   "metadata": {},
   "source": [
    "#### Rajouter une colonne dans le dataframe contenant l'embedding correspondant à l'article concerné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "186ba178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 364047 entries, 0 to 364046\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   article_id     364047 non-null  int64 \n",
      " 1   category_id    364047 non-null  int64 \n",
      " 2   created_at_ts  364047 non-null  int64 \n",
      " 3   publisher_id   364047 non-null  int64 \n",
      " 4   words_count    364047 non-null  int64 \n",
      " 5   embeddings     364047 non-null  object\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 16.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_metadata['embeddings'] = embeddings.tolist()# Reverse #np.array(df['a'].tolist())\n",
    "df_metadata['embeddings'].apply(lambda x: np.array(x))\n",
    "df_metadata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d82f8",
   "metadata": {},
   "source": [
    "#### - Fusionner les fichiers de click dans un seul dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e5f7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder =\"./data/clicks/\"\n",
    "files =[path for path in os.listdir(data_folder)]\n",
    "frames = [ pd.read_csv( os.path.join(data_folder,f) ) for f in files ]\n",
    "df_clicks = pd.concat(frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2870fc",
   "metadata": {},
   "source": [
    "#### - Fusionner les datafarame click and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8fa0dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>session_start</th>\n",
       "      <th>session_size</th>\n",
       "      <th>article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>words_count</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93863</td>\n",
       "      <td>1507865792177843</td>\n",
       "      <td>1507865792000</td>\n",
       "      <td>2</td>\n",
       "      <td>96210</td>\n",
       "      <td>1507865832925</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>209</td>\n",
       "      <td>1507798791000</td>\n",
       "      <td>0</td>\n",
       "      <td>274</td>\n",
       "      <td>[-0.6353366374969482, -0.973430335521698, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93863</td>\n",
       "      <td>1507865792177843</td>\n",
       "      <td>1507865792000</td>\n",
       "      <td>2</td>\n",
       "      <td>158094</td>\n",
       "      <td>1507865862925</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>281</td>\n",
       "      <td>1507803751000</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>[-0.20855987071990967, -0.9667428731918335, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>294036</td>\n",
       "      <td>1507865795185844</td>\n",
       "      <td>1507865795000</td>\n",
       "      <td>2</td>\n",
       "      <td>20691</td>\n",
       "      <td>1507865819095</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1507826236000</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>[-0.8065880537033081, -0.9700162410736084, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id        session_id  session_start session_size article_id  \\\n",
       "0   93863  1507865792177843  1507865792000            2      96210   \n",
       "1   93863  1507865792177843  1507865792000            2     158094   \n",
       "2  294036  1507865795185844  1507865795000            2      20691   \n",
       "\n",
       "  click_timestamp click_environment click_deviceGroup click_os click_country  \\\n",
       "0   1507865832925                 4                 3        2             1   \n",
       "1   1507865862925                 4                 3        2             1   \n",
       "2   1507865819095                 4                 3       20             1   \n",
       "\n",
       "  click_region click_referrer_type  category_id  created_at_ts  publisher_id  \\\n",
       "0           21                   2          209  1507798791000             0   \n",
       "1           21                   2          281  1507803751000             0   \n",
       "2            9                   2            9  1507826236000             0   \n",
       "\n",
       "   words_count                                         embeddings  \n",
       "0          274  [-0.6353366374969482, -0.973430335521698, -0.2...  \n",
       "1          223  [-0.20855987071990967, -0.9667428731918335, -0...  \n",
       "2          226  [-0.8065880537033081, -0.9700162410736084, -0....  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clicks.rename(columns={'click_article_id': 'article_id'}, inplace=True)\n",
    "df = pd.merge(df_clicks, df_metadata, how='left', on='article_id')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff05bfda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                0\n",
       "session_id             0\n",
       "session_start          0\n",
       "session_size           0\n",
       "article_id             0\n",
       "click_timestamp        0\n",
       "click_environment      0\n",
       "click_deviceGroup      0\n",
       "click_os               0\n",
       "click_country          0\n",
       "click_region           0\n",
       "click_referrer_type    0\n",
       "category_id            0\n",
       "created_at_ts          0\n",
       "publisher_id           0\n",
       "words_count            0\n",
       "embeddings             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vérification d'éléments vides \n",
    "df.isnull().sum()\n",
    "#dans notre cas il n'y a aucun donc aucune nécessité d'enlever des éléments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ba3319d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "#Vérification du type des colonnes utiles\n",
    "print(df.user_id.dtype)\n",
    "print(df.article_id.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eefad49",
   "metadata": {},
   "source": [
    "#### - Supprimer les utilisateurs qui ont lu moins de 3 articles  & supprimer les articles ayant été lu moins de 2 fois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdb98e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### - Supprimer les utilisateurs qui ont lu moins de 2 articles\n",
    "# Methode 1\n",
    "df_new = df.groupby(\"user_id\").filter(lambda x: len(x) > 2)\n",
    "####- supprimer les articles ayant été lus moins de 2 fois\n",
    "df_new = df_new.groupby(\"article_id\").filter(lambda x: len(x) >= 2)\n",
    "\n",
    "#### - Supprimer les utilisateurs qui ont lu moins de N articles\n",
    "# Methode 2\n",
    "#j = df['user_id'].where(df['user_id'].value_counts(dropna=True)>2)\n",
    "#new_df = df[ df['user_id'].isin(j.dropna().index) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5817f5f9",
   "metadata": {},
   "source": [
    "#### -  Séparer la base de données en train et test   \n",
    "Diviser le dataframe en train (l'historique des recherches) et test (les articles que l'on devrait recommander si la méthode était parfaite). Pour cela il faut utiliser la date des sessions pour ordonner le dataframe puis le diviser selon la proportion test_size = 0,3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "785c3855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation du Timestamp pour la date \n",
    "df_new.click_timestamp = df_new.click_timestamp.apply(lambda x : pd.Timestamp(x))\n",
    "# Utiliser directement la proportion de train et de test\n",
    "df_new= df_new.set_index(df_new['click_timestamp'])\n",
    "df_new = df_new.sort_index().reset_index(drop=True)\n",
    "divide_index = (df_new.shape[0] * 70)/100\n",
    "\n",
    "\n",
    "train = df_new[:int(divide_index)]\n",
    "test = df_new[int(divide_index):].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1383cad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vérification des valeurs numériques dans user_id \n",
      " True    2763725\n",
      "Name: user_id, dtype: int64\n",
      "Vérification des valeurs numériques dans article_id \n",
      " True    2763725\n",
      "Name: article_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check if the colums contain no numeric data\n",
    "print(\"Vérification des valeurs numériques dans user_id \\n\" ,df_new[\"user_id\"].apply(np.isreal).value_counts())\n",
    "print(\"Vérification des valeurs numériques dans article_id \\n\",df_new[\"article_id\"].apply(np.isreal).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a8bb79",
   "metadata": {},
   "source": [
    "Etant donné que les valeurs des colonnes user_id et article_id ne contiennt aucune valeur non numérique, il est simple de tranformer leur valeur numérique sans avoir besoin de convertir les colonnes cibles en type « catégorie », puis effectuer un label encoding dessus à l'aide de .cat.codes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d7af428",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['user_id'] = train['user_id'].astype('int')\n",
    "train['article_id'] = train['article_id'].astype('int')\n",
    "test['user_id'] = test['user_id'].astype('int')\n",
    "test['article_id'] = test['article_id'].astype('int')\n",
    "#print (train.info())\n",
    "#print (test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d2ca2c",
   "metadata": {},
   "source": [
    "#### -Vérifier à nouveau si train et test sont cohérents   \n",
    "Il s'agit de s'assurer que les datasets sont ordonnés en ordre croissant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ec27b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.click_timestamp[0] < test.click_timestamp[test.index[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a685af91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.click_timestamp[0] < train.click_timestamp[train.index[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c18aff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: (1934607, 17)\n",
      "Test Dataset: (829118, 17)\n",
      "Percentage train:  69.99998190847498\n",
      "Percentage test:  30.00001809152503\n"
     ]
    }
   ],
   "source": [
    "print('Train Dataset:',train.shape)\n",
    "print('Test Dataset:',test.shape)\n",
    "print(\"Percentage train: \",(train.shape[0]/(train.shape[0]+test.shape[0]))*100)\n",
    "print(\"Percentage test: \",(test.shape[0]/(train.shape[0]+test.shape[0]))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9590795e",
   "metadata": {},
   "source": [
    "#### - Supprimer les utilisateurs si aucune lecture dans la base de train (sans historique, pas de recommandation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c8cb71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18607"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#users_to_remove = [element for element in test.user_id.values if element not in train.user_id.values]\n",
    "users_to_remove = list( set(test.user_id.values).difference(set(train.user_id.values)) ) \n",
    "test =test[~test.user_id.isin(users_to_remove)]\n",
    "len(users_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d669592",
   "metadata": {},
   "source": [
    "#### - Selection des mêmes n_users à utiser dans l'entrainement de chacun des deux modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dac28ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#________Selection des mêmes n_users à utiser dans l'entrainement de chacun des deux modèles de recommandation\n",
    "n_users= 200\n",
    "sample_users = random.sample(set(train.user_id.values), n_users)\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febbb301",
   "metadata": {},
   "source": [
    "#### - Métriques d'évaluation de performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7675776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_1(intersection_categories, categories_lues_test):\n",
    "    \"\"\"categories recommandées et lues par l'utilisateur dans test\"\"\"\n",
    "    return (len(intersection_categories) /\n",
    "                       len(set(categories_lues_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a023645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_2(recommended_categories, user_categories):\n",
    "    \"\"\"categories recommandées et lues par l'utilisateur dans train\"\"\"\n",
    "    correct = 0\n",
    "    \n",
    "    for categ in recommended_categories:\n",
    "        if categ in user_categories:\n",
    "            correct +=1\n",
    "    \n",
    "    return correct/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54d478a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_3(recommended_categories, user_categories):\n",
    "    \"\"\"nouvelles categories recommandées et non lues par l'utilisateur dans train\"\"\"\n",
    "    correct = 0\n",
    "    \n",
    "    for categ in recommended_categories:\n",
    "        if categ not in user_categories:\n",
    "            correct +=1\n",
    "    \n",
    "    return correct/5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fedde4",
   "metadata": {},
   "source": [
    "## - Approche Content Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e4750ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cbfRecommender():\n",
    "\n",
    "    # Recommender les meilleurs 5 articles utulisant la siularité cosinus\n",
    "    # Calcul de performances\n",
    "    # Retourne les performances pour chaque utilisateur\n",
    "\n",
    "    def __init__(self, train, test, user_id, verbose):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.user_id = user_id\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def getFiveArticles(self):\n",
    "        liste_articles, last_article, selection, selection_results,= [],[],[],[]\n",
    "        '''\n",
    "        Fonction qui retourne 5 articles similaires en utilisant la similarité cosinus sur l'embedding du dernier \n",
    "        article vu par 'utilisateur et les embeddings restants'\n",
    "        '''\n",
    "        # get all articles read by user\n",
    "        liste_articles = self.train[self.train['user_id']\n",
    "                                    == self.user_id]['article_id'].tolist()\n",
    "        # chose the last read article\n",
    "        last_article = liste_articles[-1:]\n",
    "\n",
    "        # Dans la base de test, faire une selection d'articles qui ne contient pas les articles déjà lus\n",
    "        # Nous ne voulons pas proposer à l'utilisateur de lire quelque chose qu'il a déjà lu\n",
    "        selection = self.test[~self.test.article_id.isin(liste_articles)]\n",
    "        # Supprimer les doublons\n",
    "        selection.drop_duplicates(\n",
    "            subset='article_id', keep=\"first\", inplace=True)\n",
    "\n",
    "        # - Methode 1\n",
    "        # Récupérer l'encoding du dernier article lu\n",
    "        query_encoding = np.array(\n",
    "            self.train[self.train['article_id'] == last_article[0]]['embeddings'])[0]\n",
    "        #  spatial.distance.cosine computes the distance, and not the similarity.\n",
    "        # ======> So, you must subtract the value from 1 to get the similarity.\n",
    "        #  Calcul des similarités\n",
    "        selection['similarity_score'] = selection['embeddings'].apply(\n",
    "            lambda x: 1 - distance.cosine(x, query_encoding))\n",
    "        #  Faire le tri pour selon les grandes similarités\n",
    "        selection_results = selection.sort_values(\n",
    "            by=['similarity_score'], ascending=False)\n",
    "        #  Sélection des 5 articles les plus similaires\n",
    "        #articles1 = selection_results['article_id'][:5]\n",
    "\n",
    "        # ________ Methode 2________\n",
    "        #from sklearn.metrics.pairwise import cosine_similarity\n",
    "        #selection['similarity_score2'] = selection['embeddings'].apply(lambda x: cosine_similarity([x], [query_encoding] ))\n",
    "        #articles2 = selection.sort_values(by=['similarity_score2'], ascending=False)['article_id'][:5]\n",
    "\n",
    "        #  retourner lasSélection des 5 articles les plus similaires et leurs scores\n",
    "        return selection_results[:5]\n",
    "    \n",
    "    def affiche_reco(self, results):\n",
    "        print(\"les articles recommandés pour l'utilisateur \",self.user_id,\" Selon dernier artice lu\\n\",results[['article_id',\"similarity_score\"]])\n",
    "\n",
    "    def evaluation_context(self):\n",
    "        metric1, metric2, metric3 = 0, 0, 0\n",
    "        intersection, intersection_categories, results, articles_recommended, user_categories, last_article_category, recommended_categories = [], [],[],[],[],[],[]\n",
    "        results = self.getFiveArticles()\n",
    "        articles_recommended = results['article_id'].values\n",
    "        user_categories = self.train['category_id'][self.train.user_id == self.user_id].unique()\n",
    "        last_article_category = user_categories[-1:]\n",
    "        recommended_categories = results.category_id.unique()\n",
    "\n",
    "        # Récupération des informations suivant la base de test\n",
    "        # Les categories d'articles lus de l'utilisateur dans la base de test\n",
    "        categories_lues_test = self.test['category_id'][self.test.user_id == self.user_id].unique()\n",
    "        # Les articles de l'utilisateur lus dans la base de test\n",
    "        articles_lus_test = self.test['article_id'][self.test.user_id == self.user_id].unique()\n",
    "\n",
    "        # Les articles recommandés situés dans la liste de lecture de la base de test\n",
    "        intersection = list(set(articles_lus_test) & set(articles_recommended))\n",
    "        #print(\"Les articles recommandés situés dans la liste de lecture de la base de test: \", intersection)\n",
    "\n",
    "        # Les categories des articles recommandés situées dans la liste de lecture de la base de test\n",
    "        intersection_categories = list(\n",
    "            set(categories_lues_test) & set(recommended_categories))\n",
    "        #print(\"Les categories des articles recommandés situées dans la liste de lecture de la base de test: \", intersection_categories)\n",
    "\n",
    "        exist_test = 0  # faite pour traiter le cas où l'utilisateur n'a pas de données dans test\n",
    "        if len(set(articles_lus_test)) != 0:\n",
    "            exist_test = 1\n",
    "            # pourcentage de categories d'articles recommndés corrects en %\n",
    "            #metric1 = (len(intersection_categories) / len(set(categories_lues_test)))*100\n",
    "            metric1 = round(metric_1(intersection_categories, categories_lues_test)*100) \n",
    "        # Metrique pour identifier si je suis parvenue à trouver des articles prédits existants dans test\n",
    "        hit = 0\n",
    "        if intersection:\n",
    "            hit = 1\n",
    "        metric2 = round(metric_2(recommended_categories, user_categories)*100)\n",
    "        metric3 = round(metric_3(recommended_categories, user_categories)*100)\n",
    "        \n",
    "        if self.verbose :\n",
    "            self.affiche_reco(results) \n",
    "            print(\"metric1 = \",metric1,\"\\t metric2 = \",metric2,\" \\t metric3 =\", metric3)\n",
    "        \n",
    "        return exist_test, metric1, metric2, metric3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e84bd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbf_elapsed_time =  232.85739421844482 \t metric1 =  5.2592592592592595 \t metric2 =  19.1  \t metric3 = 11.2\n"
     ]
    }
   ],
   "source": [
    "#-------------- Test approche Content Based Filtering (approche item-item)\n",
    "performance = []\n",
    "start_time = time.time()\n",
    "for user_id in sample_users:\n",
    "    performance.append ( np.array( cbfRecommender(train, test, user_id, verbose).evaluation_context()) )\n",
    "cbf_elapsed_time = time.time() - start_time\n",
    "\n",
    "# Traitement d'affichage des métriques calculées\n",
    "j = np.array(performance)\n",
    "metric1 =np.mean( j[j[:,0]!=0][:,1], axis=0)\n",
    "part2 = np.mean(j[:, -2:], axis=0)\n",
    "part2\n",
    "metric2 =part2[0]\n",
    "metric3 = part2[1]\n",
    "print(\"cbf_elapsed_time = \",cbf_elapsed_time,\"\\t metric1 = \",metric1,\"\\t metric2 = \",metric2,\" \\t metric3 =\", metric3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d54ac3",
   "metadata": {},
   "source": [
    "### - Approche Collaborative filtering - Implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d2b6ac",
   "metadata": {},
   "source": [
    "Pour créer une recommandation du contenu de manière implicite, la seule information du choix des utilisateurs est le nombre de click sur les articles afin de déterminer leur niveau de satisfaction. Pour cela, préparer une matrice qui comporte user_id, article_id et nombre de clicks.   \n",
    "Ici, clicks est considéré comme un retour implicite des clients, il représente la préférence ou la confiance des clients pour un article spécifique.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03cc24a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>clicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16280</td>\n",
       "      <td>363925</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16280</td>\n",
       "      <td>237071</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16280</td>\n",
       "      <td>68851</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  article_id  clicks\n",
       "0    16280      363925      23\n",
       "1    16280      237071      23\n",
       "2    16280       68851      23"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the data\n",
    "data =  pd.concat( [train[\"user_id\"], train[ \"article_id\"]], axis=1, keys =[\"user_id\", \"article_id\" ])\n",
    "data = data.value_counts().to_frame('clicks').reset_index()\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1bc46a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1907161 entries, 0 to 1907160\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Dtype\n",
      "---  ------      -----\n",
      " 0   user_id     int64\n",
      " 1   article_id  int64\n",
      " 2   clicks      int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 43.7 MB\n",
      "Variation du nobre de clicks  [23 21 17 15 13 10  9  8  7  6  5  4  3  2  1]\n",
      "Ceci montre qu'il y a des articles qui sont sollicités plus que d'autres (23, 21, 17, etc)\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "print(\"Variation du nobre de clicks \",data.clicks.unique())\n",
    "print(\"Ceci montre qu'il y a des articles qui sont sollicités plus que d'autres (23, 21, 17, etc)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "382ebd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660d71bc5fbb4092a11270a0706f5314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The implicit library expects data as a item-user matrix so we\n",
    "# create two matricies, one for fitting the model (item-user) \n",
    "# and one for recommendations (user-item)\n",
    "\n",
    "sparse_item_user = sparse.csr_matrix((data['clicks'].astype(float), (data['article_id'], data['user_id'])))\n",
    "sparse_user_item = sparse.csr_matrix((data['clicks'].astype(float), (data['user_id'], data['article_id'])))\n",
    "\n",
    "\n",
    "# Initialize the als model and fit it using the sparse item-user matrix\n",
    "model = implicit.als.AlternatingLeastSquares(factors=20, regularization=0.1, iterations=20)\n",
    "\n",
    "# Calculate the confidence by multiplying it by our alpha value.\n",
    "#Initiale\n",
    "alpha_val = 15#alpha =40 selon un certain travai à vérifier si c'est réellement bon\n",
    "data_conf = (sparse_item_user * alpha_val).astype('double')\n",
    "\n",
    "\n",
    "#Fit the model\n",
    "model.fit(data_conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea530c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cfRecommender():\n",
    "\n",
    "    # Recommender les meilleurs 5 articles utilisant le collaborative filtering\n",
    "    # Calcul de performances\n",
    "    # Retourne les performances pour chaque utilisateur\n",
    "    \n",
    "    user_categories, implicit_recommended_categories, articles_lus_test, categories_lues_test, intersection_implicit, implicit_intersection_categories = [],[],[],[],[],[]\n",
    "\n",
    "\n",
    "    def __init__(self, train, test, user_id, model, sparse_user_item, verbose):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.user_id = user_id\n",
    "        self.model =  model\n",
    "        self.sparse_user_item = sparse_user_item\n",
    "        self.verbose = verbose\n",
    "              \n",
    "    def affiche_reco(self, results_implicit):\n",
    "        print(\"les articles recommandés pour l'utilisateur \",self.user_id,\"\\n\",results_implicit)\n",
    "     \n",
    "    #------------------------------\n",
    "    # CREATE USER RECOMMENDATIONS\n",
    "    #------------------------------\n",
    "     \n",
    "    def implicit_recommendation(self):\n",
    "        \"\"\"CREATE USER RECOMMENDATIONS\"\"\"\n",
    "        \n",
    "        # Use the implicit recommender.\n",
    "        recommended = model.recommend(self.user_id, self.sparse_user_item)\n",
    "        \n",
    "        implicit_articles = []\n",
    "        scores = []\n",
    "\n",
    "        # Get artist names from ids\n",
    "        for item in recommended:\n",
    "            idx, score = item\n",
    "            implicit_articles.append(idx)\n",
    "            scores.append(score)\n",
    "\n",
    "        # Create a dataframe of articles and scores\n",
    "        recommendations = pd.DataFrame({'article_id': implicit_articles , 'score': scores})\n",
    "        recommendations.drop_duplicates(subset='article_id', keep=\"first\", inplace=True)\n",
    "\n",
    "\n",
    "        #recommendations.drop_duplicates(subset=['article_id'])\n",
    "        return recommendations[:5]\n",
    "    \n",
    "    \n",
    "    def evaluation_implicit (self):\n",
    "\n",
    "        metric1, metric2, metric3 = 0,0,0\n",
    "        recommendations = []\n",
    "\n",
    "        results_implicit = self.implicit_recommendation()\n",
    "        implicit_articles = results_implicit['article_id'].values\n",
    "              \n",
    "        user_categories = self.train['category_id'][self.train.user_id == self.user_id].unique()\n",
    "\n",
    "        #print(\"implicit recommended articles: \", implicit_articles)\n",
    "        implicit_recommended_categories = self.test[self.test.article_id.isin(implicit_articles)]['category_id'].unique()\n",
    "        #print(\"implicit_recommended_categories\", implicit_recommended_categories)\n",
    "\n",
    "\n",
    "        # Récupération des informations suivant la base de test\n",
    "        articles_lus_test = self.test['article_id'][self.test.user_id==self.user_id].unique()\n",
    "        categories_lues_test = self.test['category_id'][self.test.user_id==self.user_id].unique()\n",
    "\n",
    "\n",
    "        # Les articles recommandés situés dans la liste de lecture de la base de test\n",
    "        intersection_implicit = list( set (articles_lus_test)  &  set(implicit_articles) )\n",
    "        #print(\"Les articles recommandés situés dans la liste de lecture de la base de test: \", intersection_implicit)\n",
    "\n",
    "        # Les categories des articles recommandés situées dans la liste de lecture de la base de test\n",
    "        implicit_intersection_categories = list( set (categories_lues_test)  &  set(implicit_recommended_categories) )\n",
    "        #print(\"Les categories des articles recommandés situés dans la liste de lecture de la base de test: \", implicit_intersection_categories)\n",
    "\n",
    "\n",
    "        exist_test = 0 ## faite pour traiter le cas où l'utilisateur n'a pas de données dans test\n",
    "        if len(set (articles_lus_test)) !=0 :\n",
    "            exist_test = 1\n",
    "            # pourcentage categories d'articles recommndés corrects en %\n",
    "\n",
    "            #metric1 =  (len(implicit_intersection_categories )/len(set (categories_lues_test)) )*100\n",
    "            metric1 = round(metric_1(implicit_intersection_categories, categories_lues_test)*100)\n",
    "\n",
    "        # Metrique pour identifier si je suis parvenue à trouver des articles prédits existants dans test\n",
    "        hit=0\n",
    "        if intersection_implicit: \n",
    "            hit=1\n",
    "\n",
    "        #round(metric_2(rec_items, user_1)*100)\n",
    "        metric2 = round(metric_2(implicit_recommended_categories, user_categories)*100)\n",
    "        metric3 = round(metric_3(implicit_recommended_categories, user_categories)*100)\n",
    "        \n",
    "        if self.verbose :\n",
    "            self.affiche_reco(results_implicit) \n",
    "            print(\"metric1 = \",metric1,\"\\t metric2 = \",metric2,\" \\t metric3 =\", metric3)        \n",
    "\n",
    "        return exist_test, metric1, metric2, metric3       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd7a415",
   "metadata": {},
   "source": [
    "### -Implicit Performance evaluation   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "923ddb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cf_elapsed_time =  5.622753858566284 \t metric1 =  11.898148148148149 \t metric2 =  20.6  \t metric3 = 52.1\n"
     ]
    }
   ],
   "source": [
    "#---------- Collaborative Filtering test ---------\n",
    "performance = []\n",
    "start_time = time.time()\n",
    "for user_id in sample_users:\n",
    "    performance.append ( np.array(  cfRecommender(train, test, user_id, model, sparse_user_item, verbose).evaluation_implicit() ) )\n",
    "cf_elapsed_time = time.time() - start_time\n",
    "\n",
    "# Traitement d'affichage des métriques calculées\n",
    "j = np.array(performance)\n",
    "metric1_2 =np.mean( j[j[:,0]!=0][:,1], axis=0)\n",
    "part2 = np.mean(j[:, -2:], axis=0)\n",
    "part2\n",
    "metric2_2=part2[0]\n",
    "metric3_2=part2[1]\n",
    "print(\"cf_elapsed_time = \",cf_elapsed_time,\"\\t metric1 = \",metric1_2,\"\\t metric2 = \",metric2_2,\" \\t metric3 =\", metric3_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5db2e535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                CB         CF index_col\n",
      "metric1   5.259259  11.898148   metric1\n",
      "metric2  19.100000  20.600000   metric2\n",
      "metric3  11.200000  52.100000   metric3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Comparaison méthodes de recommandation')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Récupération des résultats des différents modèles avec les données de validation\n",
    "cols = [ 'CB', 'CF']\n",
    "\n",
    "metrics = ['metric1', 'metric2','metric3']\n",
    "\n",
    "m1 = [metric1, metric1_2]# métrique 1\n",
    "m2 = [metric2, metric2_2] # métrique 2\n",
    "m3 = [metric3, metric3_2] # métrique 3\n",
    "\n",
    "\n",
    "\n",
    "numpy_data = np.array([m1,m2,m3]) \n",
    "\n",
    "info = pd.DataFrame(data=numpy_data, index=metrics, columns=cols)\n",
    "info['index_col'] = info.index\n",
    "print(info)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "info.plot(x=\"index_col\", y=[\"CB\", \"CF\"], kind=\"bar\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Métriques')\n",
    "plt.ylabel('score')\n",
    "plt.title (\"Comparaison méthodes de recommandation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2387640",
   "metadata": {},
   "source": [
    "### Enregistrement des données nécessaires pour azure functions.  \n",
    "#### train et test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd041646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#workdir = \"/Users/zeineb/lab9\"\n",
    "#chemin = workdir + \"/files\"\n",
    "#print(\"Enregistrement des fichiers train/test csv à :\", chemin)\n",
    "#try:\n",
    "#    os.makedirs(chemin, exist_ok=True)\n",
    "#except OSError as error:\n",
    "#    print(\"Save folder could not be created\")\n",
    "    \n",
    "#train.to_csv(os.path.join(chemin, \"train.csv\"), index=False)\n",
    "#dtest.to_csv(os.path.join(chemin, \"test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ba310e",
   "metadata": {},
   "source": [
    "#### Enregistrement du meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8590cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import joblib\n",
    "workdir = \"/Users/zeineb/lab9\"\n",
    "chemin = workdir + \"/files\"\n",
    "try:\n",
    "    os.makedirs(chemin, exist_ok=True)\n",
    "except OSError as error:\n",
    "    print(\"Save folder could not be created\")\n",
    "#filename = \"CF_model.joblib\"\n",
    "#joblib.dump(model,os.path.join(chemin, filename))\n",
    "\n",
    "with open(os.path.join(chemin, \"CF_model.pkl\"), 'wb') as handle:\n",
    "    pickle.dump(model, handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "757cf151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sparse_user_item\n",
    "with open(os.path.join(chemin,\"sparse_user_item.pkl\"), 'wb') as handle:\n",
    "    pickle.dump(sparse_user_item, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "285cb2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save users_arr n'est plus nécessaire car l'application mobile ne me donne plus la main de choisir\n",
    "#np.save(os.path.join(chemin,\"users_arr.npy\"), list(set(train.user_id.values)) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd099b60",
   "metadata": {},
   "source": [
    "#### #-----Load necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5e4c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----Load best model CF\n",
    "#loaded_model = joblib.load(os.path.join(chemin, filename))\n",
    "with open(os.path.join(chemin,\"CF_model.pkl\"), \"rb\") as f:\n",
    "        loaded_model = pickle.load(f)\n",
    "\n",
    "#-----Load sparse_user_item matrix\n",
    "with open(os.path.join(chemin,\"sparse_user_item.pkl\"), \"rb\") as f:\n",
    "        loaded_sparse_user_item = pickle.load(f)\n",
    "\n",
    "#-----Load list of users\n",
    "#loaded_users = np.load(os.path.join(chemin,\"users_arr.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8a9e76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158536</td>\n",
       "      <td>0.819916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124748</td>\n",
       "      <td>0.794706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124177</td>\n",
       "      <td>0.774052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124194</td>\n",
       "      <td>0.771191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156355</td>\n",
       "      <td>0.653131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id     score\n",
       "0      158536  0.819916\n",
       "1      124748  0.794706\n",
       "2      124177  0.774052\n",
       "3      124194  0.771191\n",
       "4      156355  0.653131"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------make a recommendation\n",
    "results_implicit = cfRecommender(train, test, sample_users[10], model, sparse_user_item, verbose).implicit_recommendation()\n",
    "#results_implicit = implicit_recommendation(loaded_model, loaded_sparse_user_item, sample_users[10])\n",
    "results_implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "848bead7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 80,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 195,\n",
       " 196,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 229,\n",
       " 230,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 359,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 371,\n",
       " 372,\n",
       " 373,\n",
       " 374,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 383,\n",
       " 384,\n",
       " 385,\n",
       " 386,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 391,\n",
       " 392,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 405,\n",
       " 406,\n",
       " 407,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 419,\n",
       " 420,\n",
       " 421,\n",
       " 422,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 427,\n",
       " 428,\n",
       " 429,\n",
       " 430,\n",
       " 432,\n",
       " 433,\n",
       " 434,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 447,\n",
       " 448,\n",
       " 450,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 459,\n",
       " 460,\n",
       " 463,\n",
       " 464,\n",
       " 465,\n",
       " 467,\n",
       " 468,\n",
       " 469,\n",
       " 470,\n",
       " 471,\n",
       " 472,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 477,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 481,\n",
       " 482,\n",
       " 483,\n",
       " 484,\n",
       " 485,\n",
       " 487,\n",
       " 490,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 494,\n",
       " 495,\n",
       " 496,\n",
       " 497,\n",
       " 499,\n",
       " 500,\n",
       " 501,\n",
       " 502,\n",
       " 503,\n",
       " 504,\n",
       " 505,\n",
       " 506,\n",
       " 507,\n",
       " 508,\n",
       " 509,\n",
       " 512,\n",
       " 513,\n",
       " 514,\n",
       " 515,\n",
       " 517,\n",
       " 518,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 522,\n",
       " 523,\n",
       " 524,\n",
       " 526,\n",
       " 528,\n",
       " 529,\n",
       " 530,\n",
       " 532,\n",
       " 533,\n",
       " 534,\n",
       " 535,\n",
       " 536,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 542,\n",
       " 544,\n",
       " 545,\n",
       " 546,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 550,\n",
       " 551,\n",
       " 552,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 559,\n",
       " 561,\n",
       " 562,\n",
       " 564,\n",
       " 565,\n",
       " 566,\n",
       " 567,\n",
       " 568,\n",
       " 569,\n",
       " 570,\n",
       " 571,\n",
       " 572,\n",
       " 573,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 577,\n",
       " 578,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 585,\n",
       " 586,\n",
       " 588,\n",
       " 589,\n",
       " 590,\n",
       " 592,\n",
       " 593,\n",
       " 594,\n",
       " 595,\n",
       " 596,\n",
       " 597,\n",
       " 598,\n",
       " 599,\n",
       " 601,\n",
       " 602,\n",
       " 603,\n",
       " 604,\n",
       " 605,\n",
       " 606,\n",
       " 607,\n",
       " 608,\n",
       " 609,\n",
       " 610,\n",
       " 611,\n",
       " 612,\n",
       " 613,\n",
       " 615,\n",
       " 616,\n",
       " 617,\n",
       " 618,\n",
       " 620,\n",
       " 621,\n",
       " 622,\n",
       " 623,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 627,\n",
       " 629,\n",
       " 630,\n",
       " 631,\n",
       " 632,\n",
       " 633,\n",
       " 634,\n",
       " 635,\n",
       " 636,\n",
       " 637,\n",
       " 638,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 642,\n",
       " 643,\n",
       " 644,\n",
       " 645,\n",
       " 646,\n",
       " 647,\n",
       " 648,\n",
       " 649,\n",
       " 651,\n",
       " 652,\n",
       " 653,\n",
       " 654,\n",
       " 655,\n",
       " 656,\n",
       " 657,\n",
       " 658,\n",
       " 659,\n",
       " 660,\n",
       " 662,\n",
       " 663,\n",
       " 664,\n",
       " 665,\n",
       " 667,\n",
       " 668,\n",
       " 670,\n",
       " 671,\n",
       " 672,\n",
       " 673,\n",
       " 674,\n",
       " 675,\n",
       " 676,\n",
       " 677,\n",
       " 678,\n",
       " 679,\n",
       " 680,\n",
       " 681,\n",
       " 683,\n",
       " 684,\n",
       " 685,\n",
       " 686,\n",
       " 687,\n",
       " 688,\n",
       " 690,\n",
       " 691,\n",
       " 692,\n",
       " 693,\n",
       " 695,\n",
       " 697,\n",
       " 698,\n",
       " 699,\n",
       " 700,\n",
       " 702,\n",
       " 703,\n",
       " 704,\n",
       " 706,\n",
       " 707,\n",
       " 708,\n",
       " 709,\n",
       " 710,\n",
       " 712,\n",
       " 713,\n",
       " 714,\n",
       " 715,\n",
       " 716,\n",
       " 717,\n",
       " 718,\n",
       " 719,\n",
       " 720,\n",
       " 721,\n",
       " 722,\n",
       " 723,\n",
       " 724,\n",
       " 725,\n",
       " 726,\n",
       " 727,\n",
       " 728,\n",
       " 729,\n",
       " 730,\n",
       " 731,\n",
       " 732,\n",
       " 733,\n",
       " 734,\n",
       " 735,\n",
       " 736,\n",
       " 737,\n",
       " 738,\n",
       " 740,\n",
       " 741,\n",
       " 742,\n",
       " 743,\n",
       " 744,\n",
       " 745,\n",
       " 747,\n",
       " 748,\n",
       " 749,\n",
       " 750,\n",
       " 751,\n",
       " 752,\n",
       " 754,\n",
       " 755,\n",
       " 756,\n",
       " 757,\n",
       " 759,\n",
       " 760,\n",
       " 761,\n",
       " 762,\n",
       " 763,\n",
       " 765,\n",
       " 766,\n",
       " 767,\n",
       " 769,\n",
       " 770,\n",
       " 771,\n",
       " 772,\n",
       " 773,\n",
       " 774,\n",
       " 775,\n",
       " 776,\n",
       " 779,\n",
       " 781,\n",
       " 782,\n",
       " 783,\n",
       " 784,\n",
       " 785,\n",
       " 786,\n",
       " 787,\n",
       " 789,\n",
       " 790,\n",
       " 791,\n",
       " 792,\n",
       " 793,\n",
       " 794,\n",
       " 795,\n",
       " 796,\n",
       " 797,\n",
       " 798,\n",
       " 799,\n",
       " 800,\n",
       " 801,\n",
       " 802,\n",
       " 803,\n",
       " 805,\n",
       " 806,\n",
       " 807,\n",
       " 808,\n",
       " 809,\n",
       " 810,\n",
       " 812,\n",
       " 813,\n",
       " 814,\n",
       " 815,\n",
       " 816,\n",
       " 817,\n",
       " 818,\n",
       " 819,\n",
       " 820,\n",
       " 821,\n",
       " 822,\n",
       " 823,\n",
       " 824,\n",
       " 825,\n",
       " 826,\n",
       " 827,\n",
       " 828,\n",
       " 829,\n",
       " 831,\n",
       " 834,\n",
       " 835,\n",
       " 837,\n",
       " 838,\n",
       " 839,\n",
       " 840,\n",
       " 841,\n",
       " 842,\n",
       " 843,\n",
       " 844,\n",
       " 845,\n",
       " 846,\n",
       " 847,\n",
       " 848,\n",
       " 849,\n",
       " 850,\n",
       " 851,\n",
       " 852,\n",
       " 853,\n",
       " 854,\n",
       " 855,\n",
       " 856,\n",
       " 857,\n",
       " 858,\n",
       " 860,\n",
       " 861,\n",
       " 862,\n",
       " 864,\n",
       " 865,\n",
       " 866,\n",
       " 867,\n",
       " 868,\n",
       " 869,\n",
       " 870,\n",
       " 871,\n",
       " 872,\n",
       " 873,\n",
       " 874,\n",
       " 876,\n",
       " 877,\n",
       " 878,\n",
       " 879,\n",
       " 880,\n",
       " 881,\n",
       " 882,\n",
       " 883,\n",
       " 884,\n",
       " 885,\n",
       " 886,\n",
       " 887,\n",
       " 888,\n",
       " 889,\n",
       " 890,\n",
       " 891,\n",
       " 893,\n",
       " 894,\n",
       " 895,\n",
       " 896,\n",
       " 897,\n",
       " 898,\n",
       " 899,\n",
       " 900,\n",
       " 902,\n",
       " 903,\n",
       " 904,\n",
       " 905,\n",
       " 906,\n",
       " 907,\n",
       " 908,\n",
       " 909,\n",
       " 910,\n",
       " 911,\n",
       " 912,\n",
       " 914,\n",
       " 916,\n",
       " 917,\n",
       " 918,\n",
       " 919,\n",
       " 920,\n",
       " 921,\n",
       " 922,\n",
       " 923,\n",
       " 924,\n",
       " 925,\n",
       " 926,\n",
       " 927,\n",
       " 928,\n",
       " 929,\n",
       " 931,\n",
       " 932,\n",
       " 933,\n",
       " 934,\n",
       " 935,\n",
       " 937,\n",
       " 938,\n",
       " 939,\n",
       " 940,\n",
       " 941,\n",
       " 942,\n",
       " 943,\n",
       " 944,\n",
       " 945,\n",
       " 946,\n",
       " 947,\n",
       " 948,\n",
       " 949,\n",
       " 950,\n",
       " 951,\n",
       " 952,\n",
       " 953,\n",
       " 954,\n",
       " 955,\n",
       " 956,\n",
       " 957,\n",
       " 958,\n",
       " 959,\n",
       " 960,\n",
       " 961,\n",
       " 962,\n",
       " 963,\n",
       " 964,\n",
       " 965,\n",
       " 966,\n",
       " 967,\n",
       " 968,\n",
       " 969,\n",
       " 970,\n",
       " 971,\n",
       " 972,\n",
       " 973,\n",
       " 976,\n",
       " 977,\n",
       " 978,\n",
       " 979,\n",
       " 980,\n",
       " 981,\n",
       " 982,\n",
       " 983,\n",
       " 984,\n",
       " 985,\n",
       " 986,\n",
       " 988,\n",
       " 990,\n",
       " 991,\n",
       " 992,\n",
       " 993,\n",
       " 994,\n",
       " 995,\n",
       " 996,\n",
       " 997,\n",
       " 998,\n",
       " 999,\n",
       " 1000,\n",
       " 1001,\n",
       " 1002,\n",
       " 1003,\n",
       " 1004,\n",
       " 1006,\n",
       " 1007,\n",
       " 1008,\n",
       " 1009,\n",
       " 1010,\n",
       " 1011,\n",
       " 1012,\n",
       " 1014,\n",
       " 1015,\n",
       " 1016,\n",
       " 1017,\n",
       " 1018,\n",
       " 1020,\n",
       " 1021,\n",
       " 1022,\n",
       " 1023,\n",
       " 1024,\n",
       " 1025,\n",
       " 1026,\n",
       " 1027,\n",
       " 1029,\n",
       " 1030,\n",
       " 1031,\n",
       " 1032,\n",
       " 1034,\n",
       " 1035,\n",
       " 1036,\n",
       " 1037,\n",
       " 1038,\n",
       " 1039,\n",
       " 1040,\n",
       " 1042,\n",
       " 1043,\n",
       " 1044,\n",
       " 1045,\n",
       " 1047,\n",
       " 1049,\n",
       " 1050,\n",
       " 1051,\n",
       " 1053,\n",
       " 1054,\n",
       " 1055,\n",
       " 1056,\n",
       " 1057,\n",
       " 1059,\n",
       " 1060,\n",
       " 1061,\n",
       " 1062,\n",
       " 1064,\n",
       " 1066,\n",
       " 1067,\n",
       " 1068,\n",
       " 1069,\n",
       " 1070,\n",
       " 1071,\n",
       " 1072,\n",
       " 1073,\n",
       " 1074,\n",
       " 1075,\n",
       " 1076,\n",
       " 1077,\n",
       " 1079,\n",
       " 1080,\n",
       " 1081,\n",
       " 1082,\n",
       " 1083,\n",
       " 1084,\n",
       " 1085,\n",
       " 1086,\n",
       " 1087,\n",
       " 1088,\n",
       " 1089,\n",
       " 1090,\n",
       " 1092,\n",
       " 1093,\n",
       " 1094,\n",
       " 1097,\n",
       " 1098,\n",
       " 1099,\n",
       " 1100,\n",
       " 1101,\n",
       " 1102,\n",
       " 1103,\n",
       " 1104,\n",
       " 1105,\n",
       " 1106,\n",
       " 1107,\n",
       " 1108,\n",
       " 1109,\n",
       " 1110,\n",
       " 1111,\n",
       " 1112,\n",
       " 1113,\n",
       " 1114,\n",
       " 1115,\n",
       " 1116,\n",
       " 1117,\n",
       " 1118,\n",
       " 1119,\n",
       " 1120,\n",
       " 1121,\n",
       " 1122,\n",
       " 1123,\n",
       " 1124,\n",
       " 1126,\n",
       " 1127,\n",
       " 1128,\n",
       " 1129,\n",
       " ...}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train.user_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559af9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfRecommender(train, test, 19, model, sparse_user_item, verbose).implicit_recommendation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3d92a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e76127a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2988181 entries, 0 to 2988180\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Dtype \n",
      "---  ------               ----- \n",
      " 0   user_id              object\n",
      " 1   session_id           object\n",
      " 2   session_start        object\n",
      " 3   session_size         object\n",
      " 4   article_id           object\n",
      " 5   click_timestamp      object\n",
      " 6   click_environment    object\n",
      " 7   click_deviceGroup    object\n",
      " 8   click_os             object\n",
      " 9   click_country        object\n",
      " 10  click_region         object\n",
      " 11  click_referrer_type  object\n",
      "dtypes: object(12)\n",
      "memory usage: 273.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clicks.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f77f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3636f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d97e47e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
